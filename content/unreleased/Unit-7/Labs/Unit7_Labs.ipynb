{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090aafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Labs folder if it doesn't exist\n",
    "import os\n",
    "os.makedirs('Labs', exist_ok=True)\n",
    "print(\"Labs folder created or already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d12f6d",
   "metadata": {},
   "source": [
    "## Lab 1: Reading Data from CSV Files\n",
    "\n",
    "- Download the Iris dataset CSV: [iris.csv](https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv)\n",
    "- Load the file into a Pandas DataFrame.\n",
    "- Print the shape, first 5 rows, and column names.\n",
    "- Count the number of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Download and load the Iris dataset\n",
    "url = 'https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv'\n",
    "df_iris = pd.read_csv(url)\n",
    "\n",
    "# Print shape\n",
    "print(\"Shape:\", df_iris.shape)\n",
    "\n",
    "# First 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_iris.head())\n",
    "\n",
    "# Column names\n",
    "print(\"\\nColumn names:\", list(df_iris.columns))\n",
    "\n",
    "# Missing values per column\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_iris.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acbc3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape\n",
    "print(\"Shape:\", df_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84436784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80806f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names\n",
    "print(\"\\nColumn names:\", list(df_iris.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values per column\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_iris.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15808d73",
   "metadata": {},
   "source": [
    "## Lab 2: Reading Data from Excel Files\n",
    "\n",
    "- Obtain a simple Excel file with at least two columns.\n",
    "- Load the file and display the first 3 rows.\n",
    "- List the data types of all columns.\n",
    "- Select a single column and print its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, we'll create a simple Excel file first\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Score': [85, 92, 78]\n",
    "}\n",
    "df_sample = pd.DataFrame(data)\n",
    "\n",
    "# Save to Excel\n",
    "df_sample.to_excel('Labs/sample_grades.xlsx', index=False)\n",
    "print(\"Sample Excel file created.\")\n",
    "\n",
    "# Now load it back\n",
    "df_excel = pd.read_excel('Labs/grades.xlsx')\n",
    "\n",
    "# First 3 rows\n",
    "print(\"First 3 rows:\")\n",
    "print(df_excel.head(3))\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\")\n",
    "print(df_excel.dtypes)\n",
    "\n",
    "# Select and print one column\n",
    "print(\"\\nScore column:\")\n",
    "print(df_excel['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8973b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file\n",
    "df_excel = pd.read_excel('Labs/sample_grades.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 3 rows\n",
    "print(\"First 3 rows:\")\n",
    "print(df_excel.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5da262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the data types of all columns\n",
    "print(\"\\nData types:\")\n",
    "print(df_excel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ac093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column and print its values\n",
    "print(\"\\nScore column:\")\n",
    "print(df_excel['Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bf2f6",
   "metadata": {},
   "source": [
    "## Lab 3: Reading Data from JSON Files\n",
    "\n",
    "- Create or download a small JSON file representing tabular data.\n",
    "- Load the JSON file into a DataFrame.\n",
    "- Display the last 2 rows and data types.\n",
    "- Save the DataFrame as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Create sample JSON data\n",
    "json_data = [\n",
    "    {\"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n",
    "    {\"name\": \"Bob\", \"age\": 30, \"city\": \"London\"},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Paris\"}\n",
    "]\n",
    "\n",
    "# Save to JSON file\n",
    "with open('Labs/sample_data.json', 'w') as f:\n",
    "    json.dump(json_data, f)\n",
    "print(\"Sample JSON file created.\")\n",
    "\n",
    "# Load JSON into DataFrame\n",
    "df_json = pd.read_json('Labs/sample_data.json')\n",
    "\n",
    "# Last 2 rows\n",
    "print(\"Last 2 rows:\")\n",
    "print(df_json.tail(2))\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\")\n",
    "print(df_json.dtypes)\n",
    "\n",
    "# Save as CSV\n",
    "df_json.to_csv('Labs/sample_data_from_json.csv', index=False)\n",
    "print(\"\\nSaved as CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df_json = pd.read_json('Labs/sample_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc84a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 2 rows\n",
    "print(\"Last 2 rows:\")\n",
    "print(df_json.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types\n",
    "print(\"\\nData types:\")\n",
    "print(df_json.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "df_json.to_csv('Labs/sample_data_from_json.csv', index=False)\n",
    "print(\"\\nSaved as CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46cf29",
   "metadata": {},
   "source": [
    "## Lab 4: Reading Data from Web APIs\n",
    "\n",
    "- Find an open API with simple JSON output (e.g., https://jsonplaceholder.typicode.com/users).\n",
    "- Read the data directly into a DataFrame.\n",
    "- Print the number of rows and columns.\n",
    "- Select and print the first 2 names or usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read from API\n",
    "url = 'https://jsonplaceholder.typicode.com/users'\n",
    "df_api = pd.read_json(url)\n",
    "\n",
    "# Shape\n",
    "print(\"Shape:\", df_api.shape)\n",
    "\n",
    "# First 2 usernames\n",
    "print(\"\\nFirst 2 usernames:\")\n",
    "print(df_api['username'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of rows and columns\n",
    "print(\"Shape:\", df_api.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71020357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and print the first 2 names or usernames\n",
    "print(\"\\nFirst 2 usernames:\")\n",
    "print(df_api['username'].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a979f",
   "metadata": {},
   "source": [
    "## Lab 5: Handling Missing Values\n",
    "\n",
    "- Introduce missing values into a DataFrame (e.g., using NaN).\n",
    "- Count missing values per column.\n",
    "- Drop all rows with any missing values.\n",
    "- Fill missing values in one column with that column's mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e34a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create DataFrame with missing values\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [5, np.nan, 7, 8],\n",
    "    'C': [9, 10, 11, np.nan]\n",
    "}\n",
    "df_missing = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_missing)\n",
    "\n",
    "# Count missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_missing.isnull().sum())\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_dropped = df_missing.dropna()\n",
    "print(\"\\nAfter dropping rows with missing values:\")\n",
    "print(df_dropped)\n",
    "\n",
    "# Fill missing values in column A with mean\n",
    "mean_a = df_missing['A'].mean()\n",
    "df_filled = df_missing.copy()\n",
    "df_filled['A'] = df_filled['A'].fillna(mean_a)\n",
    "print(\"\\nAfter filling missing values in A with mean:\")\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21281abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values per column\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df_missing.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with any missing values\n",
    "df_dropped = df_missing.dropna()\n",
    "print(\"\\nAfter dropping rows with missing values:\")\n",
    "print(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb98c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in one column with that column's mean\n",
    "mean_a = df_missing['A'].mean()\n",
    "df_filled = df_missing.copy()\n",
    "df_filled['A'] = df_filled['A'].fillna(mean_a)\n",
    "print(\"\\nAfter filling missing values in A with mean:\")\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8eb0e",
   "metadata": {},
   "source": [
    "## Lab 6: Handling Duplicate Records\n",
    "\n",
    "- Construct a DataFrame with intentional duplicate rows.\n",
    "- Display all duplicate rows.\n",
    "- Remove duplicates and display new shape.\n",
    "- Verify no duplicates remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee62901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame with duplicates\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Alice', 'Charlie'],\n",
    "    'Score': [85, 92, 85, 78]\n",
    "}\n",
    "df_dup = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_dup)\n",
    "\n",
    "# Display duplicate rows\n",
    "duplicates = df_dup[df_dup.duplicated()]\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(duplicates)\n",
    "\n",
    "# Remove duplicates\n",
    "df_no_dup = df_dup.drop_duplicates()\n",
    "print(\"\\nAfter removing duplicates:\")\n",
    "print(df_no_dup)\n",
    "print(\"New shape:\", df_no_dup.shape)\n",
    "\n",
    "# Verify no duplicates\n",
    "print(\"\\nAny duplicates remaining:\", df_no_dup.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73441df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all duplicate rows\n",
    "duplicates = df_dup[df_dup.duplicated()]\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf129db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates and display new shape\n",
    "df_no_dup = df_dup.drop_duplicates()\n",
    "print(\"\\nAfter removing duplicates:\")\n",
    "print(df_no_dup)\n",
    "print(\"New shape:\", df_no_dup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no duplicates remain\n",
    "print(\"\\nAny duplicates remaining:\", df_no_dup.duplicated().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944e4e1",
   "metadata": {},
   "source": [
    "## Lab 7: Identifying and Handling Outliers\n",
    "\n",
    "- Given a DataFrame with a numeric column, plot a boxplot using `df.boxplot()`.\n",
    "- Compute IQR and define outlier limits.\n",
    "- Print all outlier rows.\n",
    "- Optionally, remove outliers and compare DataFrame shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create DataFrame with outliers\n",
    "data = {'Score': [85, 92, 78, 96, 88, 200, 75, 82, 90, 150]}\n",
    "df_outliers = pd.DataFrame(data)\n",
    "\n",
    "# Boxplot\n",
    "df_outliers.boxplot(column='Score')\n",
    "plt.title('Boxplot of Scores')\n",
    "plt.show()\n",
    "\n",
    "# Compute IQR\n",
    "desc = df_outliers['Score'].describe()\n",
    "Q1 = desc['25%']\n",
    "Q3 = desc['75%']\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"IQR: {IQR}\")\n",
    "print(f\"Lower bound: {lower_bound}\")\n",
    "print(f\"Upper bound: {upper_bound}\")\n",
    "\n",
    "# Outlier rows\n",
    "outliers = df_outliers[(df_outliers['Score'] < lower_bound) | (df_outliers['Score'] > upper_bound)]\n",
    "print(\"\\nOutlier rows:\")\n",
    "print(outliers)\n",
    "\n",
    "# Remove outliers\n",
    "df_no_outliers = df_outliers[(df_outliers['Score'] >= lower_bound) & (df_outliers['Score'] <= upper_bound)]\n",
    "print(\"\\nOriginal shape:\", df_outliers.shape)\n",
    "print(\"Shape after removing outliers:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IQR and define outlier limits\n",
    "desc = df_outliers['Score'].describe()\n",
    "Q1 = desc['25%']\n",
    "Q3 = desc['75%']\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"IQR: {IQR}\")\n",
    "print(f\"Lower bound: {lower_bound}\")\n",
    "print(f\"Upper bound: {upper_bound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f009fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all outlier rows\n",
    "outliers = df_outliers[(df_outliers['Score'] < lower_bound) | (df_outliers['Score'] > upper_bound)]\n",
    "print(\"\\nOutlier rows:\")\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers and compare DataFrame shapes\n",
    "df_no_outliers = df_outliers[(df_outliers['Score'] >= lower_bound) & (df_outliers['Score'] <= upper_bound)]\n",
    "print(\"\\nOriginal shape:\", df_outliers.shape)\n",
    "print(\"Shape after removing outliers:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d07c4c",
   "metadata": {},
   "source": [
    "## Lab 8: Data Transformation with Pandas\n",
    "\n",
    "- Add a column showing normalized score (divided by max).\n",
    "- Create a boolean column \"is_high\" where score > 70.\n",
    "- Rename a column to \"total_marks\".\n",
    "- Reorder columns to bring names first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb14bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Score': [85, 92, 78]\n",
    "}\n",
    "df_trans = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_trans)\n",
    "\n",
    "# Add normalized score column\n",
    "df_trans['Normalized_Score'] = df_trans['Score'] / df_trans['Score'].max()\n",
    "\n",
    "# Create boolean column\n",
    "df_trans['is_high'] = df_trans['Score'] > 70\n",
    "\n",
    "# Rename column\n",
    "df_trans = df_trans.rename(columns={'Score': 'total_marks'})\n",
    "\n",
    "# Reorder columns\n",
    "df_trans = df_trans[['Name', 'total_marks', 'Normalized_Score', 'is_high']]\n",
    "\n",
    "print(\"\\nTransformed DataFrame:\")\n",
    "print(df_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean column \"is_high\" where score > 70\n",
    "df_trans['is_high'] = df_trans['Score'] > 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ae214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename a column to \"total_marks\"\n",
    "df_trans = df_trans.rename(columns={'Score': 'total_marks'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to bring names first\n",
    "df_trans = df_trans[['Name', 'total_marks', 'Normalized_Score', 'is_high']]\n",
    "\n",
    "print(\"\\nTransformed DataFrame:\")\n",
    "print(df_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa1f29",
   "metadata": {},
   "source": [
    "## Lab 9: Data Normalization\n",
    "\n",
    "- For a numeric column, compute normalized values using the min-max formula.\n",
    "- Add as a new column called \"norm\".\n",
    "- Verify all norm values are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d182efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "data = {'Value': [10, 20, 30, 40, 50]}\n",
    "df_norm = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_norm)\n",
    "\n",
    "# Min-max normalization\n",
    "min_val = df_norm['Value'].min()\n",
    "max_val = df_norm['Value'].max()\n",
    "df_norm['norm'] = (df_norm['Value'] - min_val) / (max_val - min_val)\n",
    "\n",
    "print(\"\\nAfter normalization:\")\n",
    "print(df_norm)\n",
    "\n",
    "# Verify values are between 0 and 1\n",
    "print(\"\\nAll norm values between 0 and 1:\", (df_norm['norm'] >= 0).all() and (df_norm['norm'] <= 1).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace92c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all norm values are between 0 and 1\n",
    "print(\"\\nAfter normalization:\")\n",
    "print(df_norm)\n",
    "\n",
    "print(\"\\nAll norm values between 0 and 1:\", (df_norm['norm'] >= 0).all() and (df_norm['norm'] <= 1).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57f02f",
   "metadata": {},
   "source": [
    "## Lab 10: Data Type Conversion with Pandas\n",
    "\n",
    "- Identify columns with wrong types (e.g., numeric data as object).\n",
    "- Convert a numeric string column to integer type.\n",
    "- Convert a date-formatted string column to datetime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00508296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame with wrong types\n",
    "data = {\n",
    "    'Score': ['85', '92', '78'],\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03']\n",
    "}\n",
    "df_types = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_types)\n",
    "print(\"\\nData types:\")\n",
    "print(df_types.dtypes)\n",
    "\n",
    "# Convert Score to int\n",
    "df_types['Score'] = df_types['Score'].astype(int)\n",
    "\n",
    "# Convert Date to datetime\n",
    "df_types['Date'] = pd.to_datetime(df_types['Date'])\n",
    "\n",
    "print(\"\\nAfter type conversion:\")\n",
    "print(df_types)\n",
    "print(\"\\nData types:\")\n",
    "print(df_types.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a numeric string column to integer type\n",
    "df_types['Score'] = df_types['Score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a date-formatted string column to datetime type\n",
    "df_types['Date'] = pd.to_datetime(df_types['Date'])\n",
    "\n",
    "print(\"\\nAfter type conversion:\")\n",
    "print(df_types)\n",
    "print(\"\\nData types:\")\n",
    "print(df_types.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bc696",
   "metadata": {},
   "source": [
    "## Lab 11: Real-World Data Cleaning Scenario\n",
    "\n",
    "- Use a sample or downloaded student grades CSV with strings, blanks, duplicates, and outliers.\n",
    "- Clean the data by:\n",
    "  - Converting score to float and filling blanks with mean\n",
    "  - Removing duplicate rows\n",
    "  - Detecting and dropping outliers using IQR\n",
    "  - Normalizing final scores\n",
    "- Output cleaned DataFrame to a new CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b290c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample messy data\n",
    "data = {\n",
    "    'Student': ['Alice', 'Bob', 'Alice', 'Charlie', 'David'],\n",
    "    'Score': ['85', '92', '', '78', '150']  # String, blank, outlier\n",
    "}\n",
    "df_messy = pd.DataFrame(data)\n",
    "print(\"Original messy DataFrame:\")\n",
    "print(df_messy)\n",
    "\n",
    "# Convert Score to float, coerce errors to NaN\n",
    "df_messy['Score'] = pd.to_numeric(df_messy['Score'], errors='coerce')\n",
    "\n",
    "# Fill missing with mean\n",
    "mean_score = df_messy['Score'].mean()\n",
    "df_messy['Score'] = df_messy['Score'].fillna(mean_score)\n",
    "\n",
    "# Remove duplicates\n",
    "df_messy = df_messy.drop_duplicates()\n",
    "\n",
    "# Remove outliers using IQR\n",
    "desc = df_messy['Score'].describe()\n",
    "Q1 = desc['25%']\n",
    "Q3 = desc['75%']\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "df_messy = df_messy[(df_messy['Score'] >= lower) & (df_messy['Score'] <= upper)]\n",
    "\n",
    "# Normalize scores\n",
    "min_score = df_messy['Score'].min()\n",
    "max_score = df_messy['Score'].max()\n",
    "df_messy['Normalized_Score'] = (df_messy['Score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_messy)\n",
    "\n",
    "# Save to CSV\n",
    "df_messy.to_csv('Labs/cleaned_grades.csv', index=False)\n",
    "print(\"\\nSaved cleaned data to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e298bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "df_messy = df_messy.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting and dropping outliers using IQR\n",
    "desc = df_messy['Grade'].describe()\n",
    "Q1 = desc['25%']\n",
    "Q3 = desc['75%']\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "df_messy = df_messy[(df_messy['Grade'] >= lower) & (df_messy['Grade'] <= upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing final scores\n",
    "min_grade = df_messy['Grade'].min()\n",
    "max_grade = df_messy['Grade'].max()\n",
    "df_messy['Normalized_Grade'] = (df_messy['Grade'] - min_grade) / (max_grade - min_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aeb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output cleaned DataFrame to a new CSV\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_messy)\n",
    "\n",
    "# Save to CSV\n",
    "df_messy.to_csv('Labs/cleaned_grades.csv', index=False)\n",
    "print(\"\\nSaved cleaned data to CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
